% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cv_class_base.R
\name{MLCrossValidation}
\alias{MLCrossValidation}
\title{R6 Class to perform cross-validation experiments}
\description{
The `MLCrossValidation` class is used to construct a cross validation object
  and to perform a k-fold cross validation for a specified machine learning
  algorithm using one distinct hyperparameter setting.
}
\details{
The `MLCrossValidation` class requires to provide a named list of predefined
  row indices for the cross validation folds, e.g., created with the function
  [splitTools::create_folds()]. This list also defines the `k` of the k-fold
  cross-validation. When wanting to perform a repeated k-fold cross
  validations, just provide a list with all repeated fold definitions, e.g.,
  when specifing the argument `m_rep` of [splitTools::create_folds()].
}
\examples{
dataset <- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))
fold_list <- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)
cv <- MLCrossValidation$new(
  learner = LearnerKnn$new(),
  fold_list = fold_list,
  seed = 123,
  ncores = 2
)
cv$learner_args <- list(
  k = 20,
  l = 0,
  test = parse(text = "fold_test$x")
)
cv$predict_args <- list(type = "response")
cv$performance_metric <- metric("bacc")
cv$performance_metric_name <- "Balanced accuracy"

# set data
cv$set_data(
  x = data.matrix(dataset[, -7]),
  y = dataset[, 7]
)

cv$execute()


## ------------------------------------------------
## Method `MLCrossValidation$new`
## ------------------------------------------------

dataset <- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))
fold_list <- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)
cv <- MLCrossValidation$new(
  learner = LearnerKnn$new(),
  fold_list = fold_list,
  seed = 123,
  ncores = 2
)


## ------------------------------------------------
## Method `MLCrossValidation$execute`
## ------------------------------------------------

dataset <- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))
fold_list <- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)
cv <- MLCrossValidation$new(
  learner = LearnerKnn$new(),
  fold_list = fold_list,
  seed = 123,
  ncores = 2
)
cv$learner_args <- list(
  k = 20,
  l = 0,
  test = parse(text = "fold_test$x")
)
cv$predict_args <- list(type = "response")
cv$performance_metric <- metric("bacc")
cv$performance_metric_name <- "Balanced accuracy"

# set data
cv$set_data(
  x = data.matrix(dataset[, -7]),
  y = dataset[, 7]
)

cv$execute()
}
\seealso{
[splitTools::create_folds()]

[splitTools::create_folds()]
}
\section{Super classes}{
\code{\link[mlexperiments:MLBase]{mlexperiments::MLBase}} -> \code{\link[mlexperiments:MLExperimentsBase]{mlexperiments::MLExperimentsBase}} -> \code{MLCrossValidation}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-MLCrossValidation-new}{\code{MLCrossValidation$new()}}
\item \href{#method-MLCrossValidation-execute}{\code{MLCrossValidation$execute()}}
\item \href{#method-MLCrossValidation-clone}{\code{MLCrossValidation$clone()}}
}
}
\if{html}{\out{
<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLExperimentsBase" data-id="set_data"><a href='../../mlexperiments/html/MLExperimentsBase.html#method-MLExperimentsBase-set_data'><code>mlexperiments::MLExperimentsBase$set_data()</code></a></span></li>
</ul>
</details>
}}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-MLCrossValidation-new"></a>}}
\if{latex}{\out{\hypertarget{method-MLCrossValidation-new}{}}}
\subsection{Method \code{new()}}{
Create a new `MLCrossValidation` object.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{MLCrossValidation$new(
  learner,
  fold_list,
  seed,
  ncores = -1L,
  return_models = FALSE
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{learner}}{An initialized learner object that inherits from class
`"MLLearnerBase"`.}

\item{\code{seed}}{An integer. Needs to be set for reproducibility purposes.}

\item{\code{ncores}}{An integer to specify the number of cores used for
parallelization (default: `-1L`).}

\item{\code{return_models}}{}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
The `MLCrossValidation` class requires to provide a named list of
  predefined row indices for the cross validation folds, e.g., created
  with the function [splitTools::create_folds()]. This list also defines
  the `k` of the k-fold cross-validation. When wanting to perform a
  repeated k-fold cross validations, just provide a list with all
  repeated fold definitions, e.g., when specifing the argument `m_rep` of
  [splitTools::create_folds()].
}

\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{dataset <- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))
fold_list <- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)
cv <- MLCrossValidation$new(
  learner = LearnerKnn$new(),
  fold_list = fold_list,
  seed = 123,
  ncores = 2
)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-MLCrossValidation-execute"></a>}}
\if{latex}{\out{\hypertarget{method-MLCrossValidation-execute}{}}}
\subsection{Method \code{execute()}}{
Execute the cross validation.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{MLCrossValidation$execute()}\if{html}{\out{</div>}}
}

\subsection{Details}{
All results of the hyperparameter tuning are saved in the field
  `$results` of the `MLTuneParameters` class. After successful execution
  of the parameter tuning, `$results` contains a list with the items
  \describe{
  \item{"fold"}{A list}
  \item{"summary"}{A data.table with the summarized results (same as
    the returned value of the `execute` method).}
  \item{"performance"}{A list}
  }
}

\subsection{Returns}{
The function returns a data.table with the results of the cross
  validation. More results are accessible from the field `$results` of
  the `MLCrossValidation` class.
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{dataset <- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))
fold_list <- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)
cv <- MLCrossValidation$new(
  learner = LearnerKnn$new(),
  fold_list = fold_list,
  seed = 123,
  ncores = 2
)
cv$learner_args <- list(
  k = 20,
  l = 0,
  test = parse(text = "fold_test$x")
)
cv$predict_args <- list(type = "response")
cv$performance_metric <- metric("bacc")
cv$performance_metric_name <- "Balanced accuracy"

# set data
cv$set_data(
  x = data.matrix(dataset[, -7]),
  y = dataset[, 7]
)

cv$execute()
}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-MLCrossValidation-clone"></a>}}
\if{latex}{\out{\hypertarget{method-MLCrossValidation-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{MLCrossValidation$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}

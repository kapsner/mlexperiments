---
title: "mlexperiments: Getting Started"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEncoding{UTF-8}
  %\VignetteIndexEntry{mlexperiments: Getting Started}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(mlexperiments)
```

```{r}
# load the dataset
dataset <- survival::colon |>
  data.table::as.data.table() |>
  na.omit()
```


```{r}
learner <- MLSurvGlmnetCox
seed <- 123
```

```{r}
surv_cols <- c("status", "time", "rx")

set.seed(seed)
surv_split_strata <- splitTools::multi_strata(
  df = dataset[, .SD, .SDcols = surv_cols],
  strategy = "kmeans",
  k = 4
)

train_test_ids <- splitTools::partition(
  y = surv_split_strata,
  p = c(train = 0.8, test = 0.2),
  type = "stratified"
)
```

```{r}
feature_cols <- colnames(dataset)[3:ncol(dataset)]
train_data <- dataset[train_test_ids$train, .SD, .SDcols = feature_cols]
test_data <- dataset[train_test_ids$test, .SD, .SDcols = feature_cols]
```

```{r}
split_vector <- splitTools::multi_strata(
  df = train_data[, .SD, .SDcols = surv_cols],
  strategy = "kmeans",
  k = 4
)
```



# Hyperparameter Optimization

## Bayesian Optimiziation

```{r}
param_list_glmnet <- expand.grid(
  alpha = seq(0, 1, 0.1)
)

glmnet_bounds <- list(alpha = c(0., 1.))
```

```{r}
surv_glmnet_cox_tuner <- TuneParameters$new(
  learner = learner,
  strategy = "bayesian",
  seed = seed
)
surv_glmnet_cox_tuner$parameter_bounds <- glmnet_bounds
surv_glmnet_cox_tuner$parameter_grid <- param_list_glmnet
surv_glmnet_cox_tuner$optim_args <- list(
  iters.n = 50L,
  kappa = 3.5,
  acq = "ucb",
  otherHalting = list(timeLimit = 30)
)

# create split-strata from training dataset
surv_glmnet_cox_tuner$split_vector <- split_vector

# set data
train_x <- model.matrix(
  ~ -1 + .,
  train_data[, .SD, .SDcols = setdiff(colnames(train_data), surv_cols[1:2])]
)
train_y <- survival::Surv(
  event = (train_data[, get("status")] |>
             as.character() |>
             as.integer()),
  time = train_data[, get("time")],
  type = "right"
)
surv_glmnet_cox_tuner$set_data(
  x = train_x,
  y = train_y
)
```


```{r}
#debug(surv_glmnet_cox_tuner$execute)
res_bayesian <- surv_glmnet_cox_tuner$execute(k = 5)
best_bayesian <- surv_glmnet_cox_tuner$results$best_setting
```

## Grid Search


```{r}
param_list_glmnet <- expand.grid(
  alpha = seq(0, 1, 0.1)
)
surv_glmnet_cox_tuner <- TuneParameters$new(
  learner = learner,
  strategy = "grid",
  seed = seed
)
surv_glmnet_cox_tuner$parameter_grid <- param_list_glmnet

# create split-strata from training dataset
surv_glmnet_cox_tuner$split_vector <- split_vector

# set data
train_x <- model.matrix(
  ~ -1 + .,
  train_data[, .SD, .SDcols = setdiff(colnames(train_data), surv_cols[1:2])]
)
train_y <- survival::Surv(
  event = (train_data[, get("status")] |>
             as.character() |>
             as.integer()),
  time = train_data[, get("time")],
  type = "right"
)
surv_glmnet_cox_tuner$set_data(
  x = train_x,
  y = train_y
)
```


```{r}
#debug(surv_glmnet_cox_tuner$execute)
res_grid <- surv_glmnet_cox_tuner$execute(k = 5)
best_grid <- surv_glmnet_cox_tuner$results$best_setting
```

## Hyperparameter Validation

```{r}
fold_list <- splitTools::create_folds(
  y = split_vector,
  k = 10,
  type = "stratified",
  seed = seed
)

surv_glmnet_cox_cv <- CrossValidation$new(
  learner = learner,
  fold_list = fold_list,
  seed = seed
)
surv_glmnet_cox_cv$learner_args <- best_grid[2:3]

# set data
train_x <- model.matrix(
  ~ -1 + .,
  train_data[, .SD, .SDcols = setdiff(colnames(train_data), surv_cols[1:2])]
)
train_y <- survival::Surv(
  event = (train_data[, get("status")] |>
             as.character() |>
             as.integer()),
  time = train_data[, get("time")],
  type = "right"
)

surv_glmnet_cox_cv$set_data(
  x = train_x,
  y = train_y
)
```

```{r}
res_cv <- surv_glmnet_cox_cv$execute_cv()
```

